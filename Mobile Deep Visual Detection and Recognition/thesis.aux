\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{dutch}{}
\babel@aux{dutch}{}
\@writefile{toc}{\contentsline {chapter}{Voorwoord}{iii}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Samenvatting}{iv}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Abstract}{v}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Inhoud}{viii}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Figurenlijst}{x}{chapter*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Tabellenlijst}{xi}{chapter*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Symbolenlijst}{xii}{chapter*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Lijst met afkortingen}{xiii}{chapter*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Situering en doelstelling}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Situering}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Probleemstelling}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Doelstellingen}{2}{section.1.3}\protected@file@percent }
\citation{koehrsen_neural_2018}
\citation{jiang_deep_2019}
\citation{8010421}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Herkenning en Detectie Algemeen}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Deep learning-gebaseerde herkenningssystemen}{3}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Herkenning}{3}{subsection.2.1.1}\protected@file@percent }
\citation{koehrsen_neural_2018}
\citation{jiang_deep_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Voorbeeld van embedding space voor boek genres.\relax }}{4}{figure.caption.10}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:embedding}{{2.1}{4}{Voorbeeld van embedding space voor boek genres.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Convolutioneel neuraal netwerk (CNN) }{4}{subsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces CNN met twee convolutie lagen en twee pooling lagen en \'e\'en fully-connected laag\relax }}{4}{figure.caption.11}\protected@file@percent }
\newlabel{fig:cnn}{{2.2}{4}{CNN met twee convolutie lagen en twee pooling lagen en \'e\'en fully-connected laag\relax }{figure.caption.11}{}}
\citation{Krizhevsky_act_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Convolutielaag waarbij een filter wordt herleid tot een output feature.\relax }}{5}{figure.caption.12}\protected@file@percent }
\newlabel{fig:conv_laag}{{2.3}{5}{Convolutielaag waarbij een filter wordt herleid tot een output feature.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces ReLu, waarbij het maximum wordt genomen van 0 en de input waarde.\relax }}{5}{figure.caption.13}\protected@file@percent }
\newlabel{fig:relu}{{2.4}{5}{ReLu, waarbij het maximum wordt genomen van 0 en de input waarde.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Max pooling waarbij er verder wordt gegaan met de maximum waarde in een 2x2 regio.\relax }}{6}{figure.caption.14}\protected@file@percent }
\newlabel{fig:maxpool}{{2.5}{6}{Max pooling waarbij er verder wordt gegaan met de maximum waarde in een 2x2 regio.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Trainen van een CNN}{6}{subsection.2.1.3}\protected@file@percent }
\newlabel{train}{{2.1.3}{6}{Trainen van een CNN}{subsection.2.1.3}{}}
\citation{Geiger_IJRR_2013}
\citation{he2015deep}
\citation{he2015deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Transfer Learning}{7}{subsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}ResNet50}{7}{subsection.2.1.5}\protected@file@percent }
\newlabel{resnet}{{2.1.5}{7}{ResNet50}{subsection.2.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces ResNet50 architectuur.\relax }}{7}{figure.caption.15}\protected@file@percent }
\newlabel{fig:resnet}{{2.6}{7}{ResNet50 architectuur.\relax }{figure.caption.15}{}}
\citation{ren_faster_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces De bovenste blok is de ID blok van de ResNet50 architectuur. De onderste is de Convolutieblok van de ResNet50 architectuur\relax }}{8}{figure.caption.16}\protected@file@percent }
\newlabel{fig:resnet_b}{{2.7}{8}{De bovenste blok is de ID blok van de ResNet50 architectuur. De onderste is de Convolutieblok van de ResNet50 architectuur\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Deep learning-gebaseerde detector}{8}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Two-stage detector}{8}{subsection.2.2.1}\protected@file@percent }
\citation{redmon_you_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Faster R-CNN\relax }}{9}{figure.caption.17}\protected@file@percent }
\newlabel{fig:faster-r-cnn}{{2.8}{9}{Faster R-CNN\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}One-stage detector}{9}{subsection.2.2.2}\protected@file@percent }
\citation{liu_ssd_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces YOLO waarbij de input is opgedeeld in een S x S rooster. En waarbij bounding box voorspellingen zijn gedaan.\relax }}{10}{figure.caption.18}\protected@file@percent }
\newlabel{fig:yolo}{{2.9}{10}{YOLO waarbij de input is opgedeeld in een S x S rooster. En waarbij bounding box voorspellingen zijn gedaan.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces One-stage detector met VGG als backbone, elke feature map met een verschillende schaal wordt ge\"evalueerd.\relax }}{11}{figure.caption.19}\protected@file@percent }
\newlabel{fig:ssd}{{2.10}{11}{One-stage detector met VGG als backbone, elke feature map met een verschillende schaal wordt ge\"evalueerd.\relax }{figure.caption.19}{}}
\citation{abadi_tensorflow_2016}
\citation{li_PyTorch_2020}
\citation{abadi_tensorflow_2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Implementatie van Herkenning en detectie op mobiel platform}{12}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Frameworks}{12}{section.3.1}\protected@file@percent }
\citation{chollet2015keras}
\citation{tensorflow2015-whitepaper}
\citation{lin2015microsoft}
\citation{duan_centernet_2019}
\citation{lin_focal_2018}
\citation{tan_efficientdet_2020}
\citation{liu_ssd_2016}
\citation{ren_faster_2016}
\citation{li_PyTorch_2020}
\citation{Facebook_PyTorch_2017}
\citation{ren_faster_2016}
\citation{lin_focal_2018}
\citation{liu_ssd_2016}
\citation{sandler_mobilenetv2_2019}
\citation{onnx_onnx_2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}TensorFlow}{13}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}PyTorch}{13}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Open Neural Network Exange (ONNX)}{13}{section.3.2}\protected@file@percent }
\citation{onnx_tf2onnx_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Een weergave van de voornaamste frameworks die naar ONNX kunnen exporten en die een ONNX model kunnen importeren.\relax }}{14}{figure.caption.20}\protected@file@percent }
\newlabel{fig:onnx}{{3.1}{14}{Een weergave van de voornaamste frameworks die naar ONNX kunnen exporten en die een ONNX model kunnen importeren.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}TensorFlow naar ONNX conversie}{14}{subsection.3.2.1}\protected@file@percent }
\citation{Google_protocol_2014}
\citation{pytorch_atensrcatennative_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}PyTorch naar ONNX conversie}{15}{subsection.3.2.2}\protected@file@percent }
\citation{tensorflow2015-whitepaper}
\citation{liu_ssd_2016}
\citation{tan_efficientdet_2020}
\citation{Google_flatbuffers_2014}
\citation{tensorflow2015-whitepaper}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Frameworks voor mobiele implementatie}{16}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}TensorFlow Lite (TFLite)}{16}{subsection.3.3.1}\protected@file@percent }
\newlabel{tf}{{3.3.1}{16}{TensorFlow Lite (TFLite)}{subsection.3.3.1}{}}
\citation{tensorflow2015-whitepaper}
\citation{tan_efficientdet_2020}
\citation{tensorflow2015-whitepaper}
\citation{Android_NNAPI_2021}
\citation{liu_ssd_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Implementatieflow van een TensorFlow model naar een mobiele implementatie. Aan de linker kant is te zien dat een TensorFlow model via de TFLite converter wordt omgezet in TFLite flatbuffer model. Het TFLite flatbuffer model kan vervolgens ge\"implementeerd worden op een client toestel waar er gebruik gemaakt kan worden van verschillende hardware componenten\relax }}{18}{figure.caption.21}\protected@file@percent }
\newlabel{fig:tflite}{{3.2}{18}{Implementatieflow van een TensorFlow model naar een mobiele implementatie. Aan de linker kant is te zien dat een TensorFlow model via de TFLite converter wordt omgezet in TFLite flatbuffer model. Het TFLite flatbuffer model kan vervolgens ge\"implementeerd worden op een client toestel waar er gebruik gemaakt kan worden van verschillende hardware componenten\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}TensorFlow.js}{18}{subsection.3.3.2}\protected@file@percent }
\citation{Facebook_PyTorch_2017}
\citation{Facebook_PyTorch_2017}
\citation{Android_NNAPI_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}PyTorch Mobile}{19}{subsection.3.3.3}\protected@file@percent }
\newlabel{trace}{{3.3.3}{19}{PyTorch Mobile}{subsection.3.3.3}{}}
\citation{onnx_onnxruntime_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Onnxruntime}{20}{subsection.3.3.4}\protected@file@percent }
\newlabel{nhwc}{{3.3.4}{20}{Onnxruntime}{lstnumber.-8.1}{}}
\citation{Apple_CoreML_2018}
\citation{luo_comparison_2020}
\citation{luo_comparison_2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.5}ONNX.js}{21}{subsection.3.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.6}CoreML}{21}{subsection.3.3.6}\protected@file@percent }
\citation{febvay_low-level_2020}
\citation{han_deep_2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.7}Gerelateerd werk}{22}{subsection.3.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Optimalisaties van neurale netwerken voor snelheid en bestandgrootte}{22}{section.3.4}\protected@file@percent }
\newlabel{optim}{{3.4}{22}{Optimalisaties van neurale netwerken voor snelheid en bestandgrootte}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Pruning}{22}{subsection.3.4.1}\protected@file@percent }
\citation{han_deep_2016}
\citation{simonyan2015deep}
\citation{Krizhevsky_act_2017}
\citation{han_deep_2016}
\citation{han_deep_2016}
\citation{han_deep_2016}
\citation{goel_survey_2020}
\citation{goel_survey_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces CNN voor en na pruning\relax }}{23}{figure.caption.22}\protected@file@percent }
\newlabel{fig:pruning}{{3.3}{23}{CNN voor en na pruning\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Parameter kwantisatie}{23}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Weight Clustering}{23}{subsection.3.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces kwantisatie van twee floating piont variabelen die worden omgezet naar twee fixed point variabelen met een gemeenschappelijke exponent.\relax }}{24}{figure.caption.23}\protected@file@percent }
\newlabel{fig:kwantizatie}{{3.4}{24}{kwantisatie van twee floating piont variabelen die worden omgezet naar twee fixed point variabelen met een gemeenschappelijke exponent.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Weight clustering: links zijn allemaal verschillende gewichten en na het het uitvoeren van weight clustering zijn er in de matrix pointers terug te vinden die wijzen kunnen wijzen naar vier verschilende waarden.\relax }}{24}{figure.caption.24}\protected@file@percent }
\newlabel{fig:clus}{{3.5}{24}{Weight clustering: links zijn allemaal verschillende gewichten en na het het uitvoeren van weight clustering zijn er in de matrix pointers terug te vinden die wijzen kunnen wijzen naar vier verschilende waarden.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Convolutionele filter compressie en matrix factorisatie}{24}{subsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Compatibiliteit van herkenningssystemen}{25}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Van TensorFlow naar mobiel framework}{25}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}TensorFlow Lite implementatie}{25}{subsection.4.1.1}\protected@file@percent }
\newlabel{tf_h_conv}{{4.1.1}{25}{TensorFlow Lite implementatie}{subsection.4.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces ResNet50 convolutieblok voor en na TFLite conversie. BatchNorm en ReLu zijn hierbij samengevoegd met de Conv2D opperaties.\relax }}{26}{figure.caption.25}\protected@file@percent }
\newlabel{fig:class_opt}{{4.1}{26}{ResNet50 convolutieblok voor en na TFLite conversie. BatchNorm en ReLu zijn hierbij samengevoegd met de Conv2D opperaties.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}ONNX implementatie}{26}{subsection.4.1.2}\protected@file@percent }
\newlabel{classonnx}{{4.1.2}{26}{ONNX implementatie}{subsection.4.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Van PyTorch naar mobiele implementatie}{27}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}PyTorch Mobile implementatie}{27}{subsection.4.2.1}\protected@file@percent }
\newlabel{py_class}{{4.2.1}{27}{PyTorch Mobile implementatie}{subsection.4.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Alle operaties die terug te vinden zijn in het ResNet50 model en hun compatibiliteit met andere frameworks\relax }}{28}{table.caption.26}\protected@file@percent }
\newlabel{tab:TFop}{{4.1}{28}{Alle operaties die terug te vinden zijn in het ResNet50 model en hun compatibiliteit met andere frameworks\relax }{table.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Alle operaties die terug te vinden zijn in het ResNet50 model en hun compatibiliteit met andere frameworks\relax }}{28}{table.caption.27}\protected@file@percent }
\newlabel{tab:PYop}{{4.2}{28}{Alle operaties die terug te vinden zijn in het ResNet50 model en hun compatibiliteit met andere frameworks\relax }{table.caption.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Conclusie}{28}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}ONNX implementatie}{29}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}ResNet50 resultaten}{29}{section.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Binaire grootte van al de ResNet50 modellen\relax }}{29}{table.caption.28}\protected@file@percent }
\newlabel{tab:class_size}{{4.3}{29}{Binaire grootte van al de ResNet50 modellen\relax }{table.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Uitvoer snelheid van de modellen in Google Colab en voor de mobiele toepassingen gebruiken we de Xiaomi T9.\relax }}{30}{table.caption.29}\protected@file@percent }
\newlabel{tab:class_speed}{{4.4}{30}{Uitvoer snelheid van de modellen in Google Colab en voor de mobiele toepassingen gebruiken we de Xiaomi T9.\relax }{table.caption.29}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Top 1 accuraatheid van de standaard en modellen voor mobiel gebruik. De modellen zijn uitgevoerd op Google Colab en Xiaomi T9.\relax }}{30}{table.caption.30}\protected@file@percent }
\newlabel{tab:class_acc}{{4.5}{30}{Top 1 accuraatheid van de standaard en modellen voor mobiel gebruik. De modellen zijn uitgevoerd op Google Colab en Xiaomi T9.\relax }{table.caption.30}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Compatibiliteit van detectie systemen}{31}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Faster-RCNN naar mobiel mobiele implementatie}{31}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Van TensorFlow naar TFLite implementatie}{31}{subsection.5.1.1}\protected@file@percent }
\newlabel{rcnn_tf}{{5.1.1}{31}{Van TensorFlow naar TFLite implementatie}{subsection.5.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Van TensorFlow naar ONNX implementatie}{34}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Van PyTorch naar mobiele implementatie}{34}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Van PyTorch naar PyTorch Mobile}{34}{subsection.5.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Alle operaties die terug te vinden zijn in het Faster-RCNN model en hun compatibiliteit met andere frameworks. De operaties van de ResNet50 backbone zijn in tabel \ref  {tab:TFop} terug te vinden.\relax }}{35}{table.caption.31}\protected@file@percent }
\newlabel{tab:TF_det_op}{{5.1}{35}{Alle operaties die terug te vinden zijn in het Faster-RCNN model en hun compatibiliteit met andere frameworks. De operaties van de ResNet50 backbone zijn in tabel \ref {tab:TFop} terug te vinden.\relax }{table.caption.31}{}}
\citation{anh_yolo3_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Van PyTorch naar ONNX implementatie}{37}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Faster-RCNN resultaten}{37}{subsection.5.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Binaire grootte van al de Faster-RCNN modellen\relax }}{37}{table.caption.32}\protected@file@percent }
\newlabel{tab:rcnn_size}{{5.2}{37}{Binaire grootte van al de Faster-RCNN modellen\relax }{table.caption.32}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Uitvoer snelheid van de modellen in Google Colab en voor de mobiele toepassingen gebruiken we de Xiaomi T9.\relax }}{37}{table.caption.33}\protected@file@percent }
\newlabel{tab:rcnn_speed}{{5.3}{37}{Uitvoer snelheid van de modellen in Google Colab en voor de mobiele toepassingen gebruiken we de Xiaomi T9.\relax }{table.caption.33}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Top 1 accuraatheid van de standaard en modellen voor mobiel gebruik. De modellen zijn uitgevoerd op Google Colab en Xiaomi T9.\relax }}{37}{table.caption.34}\protected@file@percent }
\newlabel{tab:rcnn_acc}{{5.4}{37}{Top 1 accuraatheid van de standaard en modellen voor mobiel gebruik. De modellen zijn uitgevoerd op Google Colab en Xiaomi T9.\relax }{table.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}YOLO naar mobiele implementatie}{37}{section.5.3}\protected@file@percent }
\bibstyle{apalike}
\bibdata{bibliografie}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Van TensorFlow naar TFlite implementatie}{38}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Van TensorFlow naar ONNX implementatie}{38}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Van PyTorch naar PyTorch mobile implementatie}{38}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Van PyTorch naar ONNX implementatie}{38}{subsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}YOLO resultaten}{38}{subsection.5.3.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Binaire grootte van al de YOLO modellen\relax }}{38}{table.caption.35}\protected@file@percent }
\newlabel{tab:yolo_size}{{5.5}{38}{Binaire grootte van al de YOLO modellen\relax }{table.caption.35}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces Uitvoer snelheid van de modellen in Google Colab en voor de mobiele toepassingen gebruiken we de Xiaomi T9.\relax }}{39}{table.caption.36}\protected@file@percent }
\newlabel{tab:yolo_speed}{{5.6}{39}{Uitvoer snelheid van de modellen in Google Colab en voor de mobiele toepassingen gebruiken we de Xiaomi T9.\relax }{table.caption.36}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces Top 1 accuraatheid van de standaard en modellen voor mobiel gebruik. De modellen zijn uitgevoerd op Google Colab en Xiaomi T9.\relax }}{39}{table.caption.37}\protected@file@percent }
\newlabel{tab:yolo_acc}{{5.7}{39}{Top 1 accuraatheid van de standaard en modellen voor mobiel gebruik. De modellen zijn uitgevoerd op Google Colab en Xiaomi T9.\relax }{table.caption.37}{}}
\bibcite{tensorflow2015-whitepaper}{{1}{2015}{{Abadi et~al.}}{{}}}
\bibcite{abadi_tensorflow_2016}{{2}{2016}{{Abadi et~al.}}{{}}}
\bibcite{Android_NNAPI_2021}{{3}{2021}{{Android}}{{}}}
\bibcite{anh_yolo3_2021}{{4}{2021}{{Anh}}{{}}}
\bibcite{Apple_CoreML_2018}{{5}{2018}{{Apple}}{{}}}
\bibcite{chollet2015keras}{{6}{2015}{{Chollet et~al.}}{{}}}
\bibcite{duan_centernet_2019}{{7}{2019}{{Duan et~al.}}{{}}}
\bibcite{febvay_low-level_2020}{{8}{2020}{{Febvay}}{{}}}
\bibcite{Geiger_IJRR_2013}{{9}{2013}{{Geiger et~al.}}{{}}}
\bibcite{goel_survey_2020}{{10}{2020}{{Goel et~al.}}{{}}}
\bibcite{Google_flatbuffers_2014}{{11}{2014}{{Google}}{{}}}
\bibcite{Google_protocol_2014}{{12}{2021}{{Google}}{{}}}
\bibcite{han_deep_2016}{{13}{2016}{{Han et~al.}}{{}}}
\bibcite{he2015deep}{{14}{2015}{{He et~al.}}{{}}}
\bibcite{jiang_deep_2019}{{15}{2019}{{Jiang et~al.}}{{}}}
\bibcite{koehrsen_neural_2018}{{16}{2018}{{Koehrsen}}{{}}}
\bibcite{Krizhevsky_act_2017}{{17}{2017}{{Krizhevsky et~al.}}{{}}}
\bibcite{li_PyTorch_2020}{{18}{2020}{{Li et~al.}}{{}}}
\bibcite{lin_focal_2018}{{19}{2018}{{Lin et~al.}}{{}}}
\bibcite{lin2015microsoft}{{20}{2015}{{Lin et~al.}}{{}}}
\bibcite{liu_ssd_2016}{{21}{2016}{{Liu et~al.}}{{}}}
\bibcite{luo_comparison_2020}{{22}{2020}{{Luo et~al.}}{{}}}
\bibcite{8010421}{{23}{2017}{{Ma et~al.}}{{}}}
\bibcite{onnx_onnx_2017}{{24}{2017}{{ONNX}}{{}}}
\bibcite{onnx_onnxruntime_2019}{{25}{2019}{{ONNX}}{{}}}
\bibcite{onnx_tf2onnx_2021}{{26}{2021}{{ONNX}}{{}}}
\bibcite{Facebook_PyTorch_2017}{{27}{2017}{{Paszke et~al.}}{{}}}
\bibcite{pytorch_atensrcatennative_2021}{{28}{2021}{{PyTorch}}{{}}}
\bibcite{redmon_you_2016}{{29}{2016}{{Redmon et~al.}}{{}}}
\bibcite{ren_faster_2016}{{30}{2016}{{Ren et~al.}}{{}}}
\bibcite{sandler_mobilenetv2_2019}{{31}{2019}{{Sandler et~al.}}{{}}}
\bibcite{simonyan2015deep}{{32}{2015}{{Simonyan and Zisserman}}{{}}}
\bibcite{tan_efficientdet_2020}{{33}{2020}{{Tan et~al.}}{{}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Uitleg over de appendices}{43}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\gdef \@abspage@last{57}
