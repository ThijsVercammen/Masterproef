\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{dutch}{}
\babel@aux{dutch}{}
\@writefile{toc}{\contentsline {chapter}{Voorwoord}{iii}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Samenvatting}{vi}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Abstract}{viii}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Inhoud}{xi}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Figurenlijst}{xiii}{chapter*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Tabellenlijst}{xiv}{chapter*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Lijst met afkortingen}{xv}{chapter*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Situering en doelstelling}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Situering}{1}{section.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Use-case om verschillende producten in winkelrekken te herkennen.\relax }}{1}{figure.caption.8}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:use_case}{{1.1}{1}{Use-case om verschillende producten in winkelrekken te herkennen.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Probleemstelling}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Doelstellingen}{2}{section.1.3}\protected@file@percent }
\citation{koehrsen_neural_2018}
\citation{jiang_deep_2019}
\citation{8010421}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Herkenning en Detectie Algemeen}{4}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Deep learning-gebaseerde herkenningssystemen}{4}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Herkenning}{4}{subsection.2.1.1}\protected@file@percent }
\citation{koehrsen_neural_2018}
\citation{jiang_deep_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Voorbeeld van embedding space voor boek genres.\relax }}{5}{figure.caption.9}\protected@file@percent }
\newlabel{fig:embedding}{{2.1}{5}{Voorbeeld van embedding space voor boek genres.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Convolutioneel neuraal netwerk (CNN) }{5}{subsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces CNN met twee convolutie lagen en twee pooling lagen en \'e\'en fully-connected laag\relax }}{5}{figure.caption.10}\protected@file@percent }
\newlabel{fig:cnn}{{2.2}{5}{CNN met twee convolutie lagen en twee pooling lagen en \'e\'en fully-connected laag\relax }{figure.caption.10}{}}
\citation{Krizhevsky_act_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Convolutielaag waarbij de input vermenigvuldigd wordt met een kernel. De vermenigvuldigde inputwaardes worden vervolgens herleid tot een enkele waarde. Vervolgens zal de filter opschuiven en opnieuw deze actie uitvoeren.\relax }}{6}{figure.caption.11}\protected@file@percent }
\newlabel{fig:conv_laag}{{2.3}{6}{Convolutielaag waarbij de input vermenigvuldigd wordt met een kernel. De vermenigvuldigde inputwaardes worden vervolgens herleid tot een enkele waarde. Vervolgens zal de filter opschuiven en opnieuw deze actie uitvoeren.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces ReLu, waarbij het maximum wordt genomen van 0 en de input waarde.\relax }}{6}{figure.caption.12}\protected@file@percent }
\newlabel{fig:relu}{{2.4}{6}{ReLu, waarbij het maximum wordt genomen van 0 en de input waarde.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Maxpooling waarbij er verder wordt gegaan met de maximum waarde in een 2x2 regio.\relax }}{7}{figure.caption.13}\protected@file@percent }
\newlabel{fig:maxpool}{{2.5}{7}{Maxpooling waarbij er verder wordt gegaan met de maximum waarde in een 2x2 regio.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Trainen van een CNN}{7}{subsection.2.1.3}\protected@file@percent }
\newlabel{train}{{2.1.3}{7}{Trainen van een CNN}{subsection.2.1.3}{}}
\citation{Geiger_IJRR_2013}
\citation{he2015deep}
\citation{he2015deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Transfer Learning}{8}{subsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}ResNet50}{8}{subsection.2.1.5}\protected@file@percent }
\newlabel{resnet}{{2.1.5}{8}{ResNet50}{subsection.2.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces ResNet50 architectuur met de al de operaties. Ook zijn er 2 verschillende ResNet blokken terug te vinden het convolutieblok en het ID-blok.\relax }}{9}{figure.caption.14}\protected@file@percent }
\newlabel{fig:resnet}{{2.6}{9}{ResNet50 architectuur met de al de operaties. Ook zijn er 2 verschillende ResNet blokken terug te vinden het convolutieblok en het ID-blok.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces De bovenste blok is de ID blok van de ResNet50 architectuur. De onderste is de Convolutieblok van de ResNet50 architectuur\relax }}{9}{figure.caption.15}\protected@file@percent }
\newlabel{fig:resnet_b}{{2.7}{9}{De bovenste blok is de ID blok van de ResNet50 architectuur. De onderste is de Convolutieblok van de ResNet50 architectuur\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Deep learning-gebaseerde detector}{9}{section.2.2}\protected@file@percent }
\citation{ren_faster_2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Two-stage detector}{10}{subsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Faster R-CNN\relax }}{10}{figure.caption.16}\protected@file@percent }
\newlabel{fig:faster-r-cnn}{{2.8}{10}{Faster R-CNN\relax }{figure.caption.16}{}}
\citation{redmon_you_2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}One-stage detector}{11}{subsection.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces YOLO waarbij de input is opgedeeld in een S x S rooster. En waarbij bounding box voorspellingen zijn gedaan.\relax }}{11}{figure.caption.17}\protected@file@percent }
\newlabel{fig:yolo}{{2.9}{11}{YOLO waarbij de input is opgedeeld in een S x S rooster. En waarbij bounding box voorspellingen zijn gedaan.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Mean avarage precision (mAP)}{11}{subsection.2.2.3}\protected@file@percent }
\newlabel{map}{{2.2.3}{11}{Mean avarage precision (mAP)}{subsection.2.2.3}{}}
\citation{eavise_eavise_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces In deze afbeelding kunnen we zien hoe de overlap/IoU wordt berekend\relax }}{12}{figure.caption.18}\protected@file@percent }
\newlabel{fig:iou}{{2.10}{12}{In deze afbeelding kunnen we zien hoe de overlap/IoU wordt berekend\relax }{figure.caption.18}{}}
\citation{abadi_tensorflow_2016}
\citation{li_PyTorch_2020}
\citation{abadi_tensorflow_2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Implementatie van herkenning en detectie op een mobiel platform}{13}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Frameworks}{13}{section.3.1}\protected@file@percent }
\citation{chollet2015keras}
\citation{tensorflow2015-whitepaper}
\citation{lin2015microsoft}
\citation{duan_centernet_2019}
\citation{lin_focal_2018}
\citation{tan_efficientdet_2020}
\citation{liu_ssd_2016}
\citation{ren_faster_2016}
\citation{li_PyTorch_2020}
\citation{Facebook_PyTorch_2017}
\citation{ren_faster_2016}
\citation{lin_focal_2018}
\citation{liu_ssd_2016}
\citation{sandler_mobilenetv2_2019}
\citation{onnx_onnx_2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}TensorFlow}{14}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}PyTorch}{14}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Open Neural Network Exange (ONNX)}{14}{section.3.2}\protected@file@percent }
\citation{onnx_tf2onnx_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Een weergave van de voornaamste frameworks die naar ONNX kunnen exporten en die een ONNX model kunnen importeren.\relax }}{15}{figure.caption.19}\protected@file@percent }
\newlabel{fig:onnx}{{3.1}{15}{Een weergave van de voornaamste frameworks die naar ONNX kunnen exporten en die een ONNX model kunnen importeren.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}TensorFlow naar ONNX conversie}{15}{subsection.3.2.1}\protected@file@percent }
\citation{Google_protocol_2014}
\citation{pytorch_atensrcatennative_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}PyTorch naar ONNX conversie}{16}{subsection.3.2.2}\protected@file@percent }
\citation{tensorflow2015-whitepaper}
\citation{liu_ssd_2016}
\citation{tan_efficientdet_2020}
\citation{Google_flatbuffers_2014}
\citation{tensorflow2015-whitepaper}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Frameworks voor mobiele implementatie}{17}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}TensorFlow Lite (TFLite)}{17}{subsection.3.3.1}\protected@file@percent }
\newlabel{tf}{{3.3.1}{17}{TensorFlow Lite (TFLite)}{subsection.3.3.1}{}}
\citation{tensorflow2015-whitepaper}
\citation{tan_efficientdet_2020}
\citation{tensorflow2015-whitepaper}
\citation{Android_NNAPI_2021}
\citation{liu_ssd_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Implementatieflow van een TensorFlow model naar een mobiele implementatie. Aan de linker kant is te zien dat een TensorFlow model via de TFLite converter wordt omgezet in TFLite flatbuffer model. Het TFLite flatbuffer model kan vervolgens ge\"implementeerd worden op een toestel waar het gebruik kan maken van verschillende hardware componenten\relax }}{19}{figure.caption.20}\protected@file@percent }
\newlabel{fig:tflite}{{3.2}{19}{Implementatieflow van een TensorFlow model naar een mobiele implementatie. Aan de linker kant is te zien dat een TensorFlow model via de TFLite converter wordt omgezet in TFLite flatbuffer model. Het TFLite flatbuffer model kan vervolgens ge\"implementeerd worden op een toestel waar het gebruik kan maken van verschillende hardware componenten\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}TensorFlow.js}{19}{subsection.3.3.2}\protected@file@percent }
\citation{Facebook_PyTorch_2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}PyTorch Mobile}{20}{subsection.3.3.3}\protected@file@percent }
\newlabel{trace}{{3.3.3}{20}{PyTorch Mobile}{subsection.3.3.3}{}}
\citation{Facebook_PyTorch_2017}
\citation{Android_NNAPI_2021}
\citation{onnx_onnxruntime_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Onnxruntime}{21}{subsection.3.3.4}\protected@file@percent }
\citation{Apple_CoreML_2018}
\newlabel{nhwc}{{3.3.4}{22}{Onnxruntime}{lstnumber.-8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.5}ONNX.js}{22}{subsection.3.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.6}CoreML}{22}{subsection.3.3.6}\protected@file@percent }
\citation{luo_comparison_2020}
\citation{luo_comparison_2020}
\citation{luo_comparison_2020}
\citation{febvay_low-level_2020}
\citation{khan_mace_2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.7}Gerelateerd werk}{23}{subsection.3.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Optimalisaties van neurale netwerken voor snelheid en bestandgrootte}{23}{section.3.4}\protected@file@percent }
\newlabel{optim}{{3.4}{23}{Optimalisaties van neurale netwerken voor snelheid en bestandgrootte}{section.3.4}{}}
\citation{han_deep_2016}
\citation{han_deep_2016}
\citation{simonyan2015deep}
\citation{Krizhevsky_act_2017}
\citation{han_deep_2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Pruning}{24}{subsection.3.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces CNN voor en na pruning\relax }}{24}{figure.caption.21}\protected@file@percent }
\newlabel{fig:pruning}{{3.3}{24}{CNN voor en na pruning\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Parameter kwantisatie}{24}{subsection.3.4.2}\protected@file@percent }
\newlabel{quant}{{3.4.2}{24}{Parameter kwantisatie}{subsection.3.4.2}{}}
\citation{han_deep_2016}
\citation{han_deep_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces kwantisatie van twee floating piont variabelen die worden omgezet naar twee fixed point variabelen met een gemeenschappelijke exponent.\relax }}{25}{figure.caption.22}\protected@file@percent }
\newlabel{fig:kwantizatie}{{3.4}{25}{kwantisatie van twee floating piont variabelen die worden omgezet naar twee fixed point variabelen met een gemeenschappelijke exponent.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Weight Clustering}{25}{subsection.3.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Weight clustering: links zien we verschillende gewichten en na het het uitvoeren van weight clustering zijn er in de matrix pointers terug te vinden die wijzen naar een set van vier vaste waarden.\relax }}{25}{figure.caption.23}\protected@file@percent }
\newlabel{fig:clus}{{3.5}{25}{Weight clustering: links zien we verschillende gewichten en na het het uitvoeren van weight clustering zijn er in de matrix pointers terug te vinden die wijzen naar een set van vier vaste waarden.\relax }{figure.caption.23}{}}
\citation{deng_2009_imagenet}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Compatibiliteit van herkenningssystemen}{26}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Van TensorFlow naar mobiel framework}{26}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}TensorFlow Lite implementatie}{26}{subsection.4.1.1}\protected@file@percent }
\newlabel{tf_h_conv}{{4.1.1}{26}{TensorFlow Lite implementatie}{subsection.4.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces ResNet50 convolutieblok voor en na TFLite conversie. BatchNorm en ReLu zijn hierbij samengevoegd met de Conv2D opperaties.\relax }}{27}{figure.caption.24}\protected@file@percent }
\newlabel{fig:class_opt}{{4.1}{27}{ResNet50 convolutieblok voor en na TFLite conversie. BatchNorm en ReLu zijn hierbij samengevoegd met de Conv2D opperaties.\relax }{figure.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Alle operaties die terug te vinden zijn in het TensorFlow ResNet50 model en hun compatibiliteit met andere frameworks\relax }}{28}{table.caption.25}\protected@file@percent }
\newlabel{tab:TFop}{{4.1}{28}{Alle operaties die terug te vinden zijn in het TensorFlow ResNet50 model en hun compatibiliteit met andere frameworks\relax }{table.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}ONNX implementatie}{28}{subsection.4.1.2}\protected@file@percent }
\newlabel{classonnx}{{4.1.2}{28}{ONNX implementatie}{subsection.4.1.2}{}}
\citation{deng_2009_imagenet}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Van PyTorch naar mobiele implementatie}{29}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}PyTorch Mobile implementatie}{29}{subsection.4.2.1}\protected@file@percent }
\newlabel{py_class}{{4.2.1}{29}{PyTorch Mobile implementatie}{subsection.4.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Alle operaties die terug te vinden zijn in het Torchvision ResNet50 model en hun compatibiliteit met andere frameworks\relax }}{30}{table.caption.26}\protected@file@percent }
\newlabel{tab:PYop}{{4.2}{30}{Alle operaties die terug te vinden zijn in het Torchvision ResNet50 model en hun compatibiliteit met andere frameworks\relax }{table.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}ONNX implementatie}{30}{subsection.4.2.2}\protected@file@percent }
\newlabel{py_onnx}{{4.2.2}{30}{ONNX implementatie}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Samenvatting}{31}{section.4.3}\protected@file@percent }
\citation{lin2015microsoft}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Compatibiliteit van detectie systemen}{32}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Faster-RCNN naar mobiel mobiele implementatie}{32}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Van TensorFlow naar TFLite implementatie}{32}{subsection.5.1.1}\protected@file@percent }
\newlabel{rcnn_tf}{{5.1.1}{32}{Van TensorFlow naar TFLite implementatie}{subsection.5.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Van TensorFlow naar ONNX implementatie}{35}{subsection.5.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Alle operaties die terug te vinden zijn in het TensorFlow Faster-RCNN model en hun compatibiliteit met het ONNX en TFLite framework. De operaties van de ResNet50 backbone zijn in tabel \ref  {tab:TFop} terug te vinden.\relax }}{36}{table.caption.27}\protected@file@percent }
\newlabel{tab:TF_det_op}{{5.1}{36}{Alle operaties die terug te vinden zijn in het TensorFlow Faster-RCNN model en hun compatibiliteit met het ONNX en TFLite framework. De operaties van de ResNet50 backbone zijn in tabel \ref {tab:TFop} terug te vinden.\relax }{table.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Van PyTorch naar PyTorch Mobile}{36}{subsection.5.1.3}\protected@file@percent }
\citation{Facebook_detectron2_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Van PyTorch naar ONNX implementatie}{38}{subsection.5.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Samenvatting}{38}{subsection.5.1.5}\protected@file@percent }
\citation{redmon_yolov3_2018}
\citation{darknet13}
\citation{anh_yolo3_2021}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}YOLO naar mobiele implementatie}{39}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Van TensorFlow naar TFlite implementatie}{39}{subsection.5.2.1}\protected@file@percent }
\citation{kathuria_pytorch_2022}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Van TensorFlow naar ONNX implementatie}{40}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Van PyTorch naar PyTorch mobile implementatie}{40}{subsection.5.2.3}\protected@file@percent }
\citation{roeder_lutzroedernetron_2022}
\citation{anh_yolo3_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Van PyTorch naar ONNX implementatie}{41}{subsection.5.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Samenvatting}{41}{subsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Resultaten}{43}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}De bestandsgrootte van de verschillende modellen}{43}{section.6.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces De bestandsgrootte van de verschillende modellen\relax }}{43}{table.caption.28}\protected@file@percent }
\newlabel{tab:size}{{6.1}{43}{De bestandsgrootte van de verschillende modellen\relax }{table.caption.28}{}}
\citation{recht2019imagenet}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}De uitvoersnelheid van de verschillende modellen}{44}{section.6.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces De uitvoersnelheid van de verschillende modellen in Google Colaboratory en in de mobiele omgeving. Als mobiele omgeving gebruiken we de Xiaomi T9.\relax }}{44}{table.caption.29}\protected@file@percent }
\newlabel{tab:speed}{{6.2}{44}{De uitvoersnelheid van de verschillende modellen in Google Colaboratory en in de mobiele omgeving. Als mobiele omgeving gebruiken we de Xiaomi T9.\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}De accuraatheid van de verschillende modellen}{44}{section.6.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Top 1 accuraatheid voor het standaard, mobiel en ONNX model.\relax }}{45}{table.caption.30}\protected@file@percent }
\newlabel{tab:class_acc}{{6.3}{45}{Top 1 accuraatheid voor het standaard, mobiel en ONNX model.\relax }{table.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.4}{\ignorespaces Mean avarage precision van de modellen uitgevoerd op Google Colab en Xiaomi T9.\relax }}{45}{table.caption.31}\protected@file@percent }
\newlabel{tab:rcnn_acc}{{6.4}{45}{Mean avarage precision van de modellen uitgevoerd op Google Colab en Xiaomi T9.\relax }{table.caption.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Conclusie}{45}{section.6.4}\protected@file@percent }
\bibstyle{apalike}
\bibdata{bibliografie}
\bibcite{Facebook_detectron2_2021}{{1}{2021}{{Fac}}{{}}}
\bibcite{tensorflow2015-whitepaper}{{2}{2015}{{Abadi et~al.}}{{}}}
\bibcite{abadi_tensorflow_2016}{{3}{2016}{{Abadi et~al.}}{{}}}
\bibcite{Android_NNAPI_2021}{{4}{2021}{{Android}}{{}}}
\bibcite{anh_yolo3_2021}{{5}{2021}{{Anh}}{{}}}
\bibcite{Apple_CoreML_2018}{{6}{2018}{{Apple}}{{}}}
\bibcite{chollet2015keras}{{7}{2015}{{Chollet et~al.}}{{}}}
\bibcite{deng_2009_imagenet}{{8}{2009}{{Deng et~al.}}{{}}}
\bibcite{duan_centernet_2019}{{9}{2019}{{Duan et~al.}}{{}}}
\bibcite{eavise_eavise_2020}{{10}{2020}{{EAVISE}}{{}}}
\bibcite{febvay_low-level_2020}{{11}{2020}{{Febvay}}{{}}}
\bibcite{Geiger_IJRR_2013}{{12}{2013}{{Geiger et~al.}}{{}}}
\bibcite{Google_flatbuffers_2014}{{13}{2014}{{Google}}{{}}}
\bibcite{Google_protocol_2014}{{14}{2021}{{Google}}{{}}}
\bibcite{han_deep_2016}{{15}{2016}{{Han et~al.}}{{}}}
\bibcite{he2015deep}{{16}{2015}{{He et~al.}}{{}}}
\bibcite{jiang_deep_2019}{{17}{2019}{{Jiang et~al.}}{{}}}
\bibcite{kathuria_pytorch_2022}{{18}{2022}{{Kathuria}}{{}}}
\bibcite{khan_mace_2020}{{19}{2020}{{Khan}}{{}}}
\bibcite{koehrsen_neural_2018}{{20}{2018}{{Koehrsen}}{{}}}
\bibcite{Krizhevsky_act_2017}{{21}{2017}{{Krizhevsky et~al.}}{{}}}
\bibcite{li_PyTorch_2020}{{22}{2020}{{Li et~al.}}{{}}}
\bibcite{lin_focal_2018}{{23}{2018}{{Lin et~al.}}{{}}}
\bibcite{lin2015microsoft}{{24}{2015}{{Lin et~al.}}{{}}}
\bibcite{liu_ssd_2016}{{25}{2016}{{Liu et~al.}}{{}}}
\bibcite{luo_comparison_2020}{{26}{2020}{{Luo et~al.}}{{}}}
\bibcite{8010421}{{27}{2017}{{Ma et~al.}}{{}}}
\bibcite{onnx_onnx_2017}{{28}{2017}{{ONNX}}{{}}}
\bibcite{onnx_onnxruntime_2019}{{29}{2019}{{ONNX}}{{}}}
\bibcite{onnx_tf2onnx_2021}{{30}{2021}{{ONNX}}{{}}}
\bibcite{Facebook_PyTorch_2017}{{31}{2017}{{Paszke et~al.}}{{}}}
\bibcite{pytorch_atensrcatennative_2021}{{32}{2021}{{PyTorch}}{{}}}
\bibcite{recht2019imagenet}{{33}{2019}{{Recht et~al.}}{{}}}
\bibcite{darknet13}{{34}{2016}{{Redmon}}{{}}}
\bibcite{redmon_you_2016}{{35}{2016}{{Redmon et~al.}}{{}}}
\bibcite{redmon_yolov3_2018}{{36}{2018}{{Redmon and Farhadi}}{{}}}
\bibcite{ren_faster_2016}{{37}{2016}{{Ren et~al.}}{{}}}
\bibcite{roeder_lutzroedernetron_2022}{{38}{2022}{{Roeder}}{{}}}
\bibcite{sandler_mobilenetv2_2019}{{39}{2019}{{Sandler et~al.}}{{}}}
\bibcite{simonyan2015deep}{{40}{2015}{{Simonyan and Zisserman}}{{}}}
\bibcite{tan_efficientdet_2020}{{41}{2020}{{Tan et~al.}}{{}}}
\gdef \@abspage@last{65}
